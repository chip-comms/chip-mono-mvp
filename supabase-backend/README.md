# Meeting Intelligence Backend

Backend logic for the meeting intelligence assistant. This contains all the business logic, AI processing, and storage adapters.

## Structure

```
supabase-backend/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ ai/               # Portable AI processing (works in Node & Deno)
â”‚   â”‚   â”œâ”€â”€ transcription.ts   # Whisper API integration
â”‚   â”‚   â”œâ”€â”€ analysis.ts        # GPT-4 analysis
â”‚   â”‚   â””â”€â”€ metrics.ts         # Communication metrics calculation
â”‚   â”œâ”€â”€ storage/          # Storage adapters
â”‚   â”‚   â””â”€â”€ local.ts           # Local filesystem implementation
â”‚   â”œâ”€â”€ data/             # Data adapters
â”‚   â”‚   â””â”€â”€ local.ts           # Local JSON file implementation
â”‚   â”œâ”€â”€ types.ts          # TypeScript type definitions
â”‚   â””â”€â”€ config.ts         # Configuration
â”œâ”€â”€ storage/              # Local file storage
â”‚   â””â”€â”€ uploads/          # Uploaded files
â””â”€â”€ data/                 # Local JSON database
    â”œâ”€â”€ recordings.json   # Recordings metadata
    â””â”€â”€ intelligence/     # Intelligence results
```

## Setup

```bash
# Install dependencies
npm install

# Create environment file
cp .env.example .env.local
# Edit .env.local and add your OPENAI_API_KEY

# Create storage directories
mkdir -p storage/uploads
mkdir -p data/intelligence
echo "[]" > data/recordings.json

# Install FFmpeg (required for video processing)
# macOS:
brew install ffmpeg
# Ubuntu:
sudo apt install ffmpeg
```

## Usage

The backend code is imported by Next.js API routes in the frontend application. When you run the frontend dev server, it will use these modules.

## Migration to Supabase Edge Functions

When ready to deploy, convert the API routes to Edge Functions:

### What Stays the Same

- âœ… All `lib/ai/*` modules (100% portable)
- âœ… `lib/types.ts` (shared types)
- âœ… `lib/config.ts` (just update env vars)

### What Changes

- ðŸ”„ `lib/storage/local.ts` â†’ Create `lib/storage/supabase.ts`
- ðŸ”„ `lib/data/local.ts` â†’ Create `lib/data/supabase.ts`
- ðŸ”„ API routes â†’ Edge Functions (different syntax, same logic)

The portable AI modules can be directly imported into Deno edge functions!

## Testing AI Modules

You can test the portable modules independently:

```typescript
import { transcribeAudio } from './lib/ai/transcription';
import { analyzeTranscript } from './lib/ai/analysis';
import { calculateCommunicationMetrics } from './lib/ai/metrics';

// Load your audio file
const audioFile = new File([buffer], 'test.mp3', { type: 'audio/mpeg' });

// Transcribe
const transcript = await transcribeAudio(audioFile, process.env.OPENAI_API_KEY);

// Analyze
const analysis = await analyzeTranscript(
  transcript,
  process.env.OPENAI_API_KEY
);

// Calculate metrics
const metrics = calculateCommunicationMetrics(transcript);

console.log({ transcript, analysis, metrics });
```

## Dependencies

- `openai` - OpenAI API client
- `fluent-ffmpeg` - FFmpeg wrapper for audio extraction
- Standard Node.js `fs`, `path` modules (will be replaced for Deno)
